{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "pwd"
      ],
      "metadata": {
        "id": "W1riec4BtMw_",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "fa206556-7f40-41b7-c8d0-e67372679e7d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V0tge4tuq0h_",
        "outputId": "5b1975ea-7819-4321-9ad7-98d41bb2c005"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "anxiety: 10 files\n",
            "contentment: 11 files\n",
            "exuberance: 11 files\n",
            ".ipynb_checkpoints: 0 files\n",
            "depression: 13 files\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "# Path to the main directory\n",
        "main_dir = './sample_data/test'\n",
        "\n",
        "# List to store counts of files in each folder\n",
        "mood_counts = {}\n",
        "\n",
        "# Loop through each folder (subdirectory) in the main directory\n",
        "for mood_folder in os.listdir(main_dir):\n",
        "    mood_path = os.path.join(main_dir, mood_folder)\n",
        "\n",
        "    # Check if it's a directory\n",
        "    if os.path.isdir(mood_path):\n",
        "        # Count the number of files in the directory\n",
        "        file_count = len([file for file in os.listdir(mood_path) if os.path.isfile(os.path.join(mood_path, file))])\n",
        "        mood_counts[mood_folder] = file_count\n",
        "\n",
        "# Display the count of files in each folder\n",
        "for mood, count in mood_counts.items():\n",
        "    print(f\"{mood}: {count} files\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g4tJaztZU_L8"
      },
      "outputs": [],
      "source": [
        "#gpu ram clearing\n",
        "import torch\n",
        "torch.cuda.empty_cache()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#system ram clearing\n",
        "import gc\n",
        "gc.collect()\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from keras.models import Sequential"
      ],
      "metadata": {
        "id": "ZMvIo3tQc5W4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers torchaudio librosa pandas\n",
        "import gc\n",
        "import os\n",
        "import torch\n",
        "import torchaudio\n",
        "import pandas as pd\n",
        "from transformers import AutoModel, AutoTokenizer\n",
        "from transformers import Wav2Vec2FeatureExtractor\n",
        "from transformers import Wav2Vec2ForCTC\n",
        "import librosa\n",
        "import numpy as np\n",
        "\n",
        "# Set your Hugging Face API token\n",
        "os.environ['HF_TOKEN'] = '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'  # Replace with your actual HF token\n",
        "\n",
        "# Check if a GPU is available and set the device accordingly\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "if device.type == \"cuda\":\n",
        "    print(\"GPU is available and will be used.\")\n",
        "else:\n",
        "    print(\"GPU is not available; using CPU.\")\n",
        "\n",
        "# loading our model weights\n",
        "model = AutoModel.from_pretrained(\"m-a-p/MERT-v1-330M\", trust_remote_code=True)\n",
        "# loading the corresponding preprocessor config\n",
        "processor = Wav2Vec2FeatureExtractor.from_pretrained(\"m-a-p/MERT-v1-330M\",trust_remote_code=True)\n",
        "\n",
        " #Move the model to the device (GPU if available)\n",
        "model = model.to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0V0iSppDdPSn",
        "outputId": "02713cb7-c28b-4299-ceb9-a5f621334e15"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.44.2)\n",
            "Requirement already satisfied: torchaudio in /usr/local/lib/python3.10/dist-packages (2.4.1+cu121)\n",
            "Requirement already satisfied: librosa in /usr/local/lib/python3.10/dist-packages (0.10.2.post1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (2.1.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.16.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.24.7)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.9.11)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.5)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.5)\n",
            "Requirement already satisfied: torch==2.4.1 in /usr/local/lib/python3.10/dist-packages (from torchaudio) (2.4.1+cu121)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch==2.4.1->torchaudio) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch==2.4.1->torchaudio) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch==2.4.1->torchaudio) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch==2.4.1->torchaudio) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch==2.4.1->torchaudio) (2024.6.1)\n",
            "Requirement already satisfied: audioread>=2.1.9 in /usr/local/lib/python3.10/dist-packages (from librosa) (3.0.1)\n",
            "Requirement already satisfied: scipy>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from librosa) (1.13.1)\n",
            "Requirement already satisfied: scikit-learn>=0.20.0 in /usr/local/lib/python3.10/dist-packages (from librosa) (1.5.2)\n",
            "Requirement already satisfied: joblib>=0.14 in /usr/local/lib/python3.10/dist-packages (from librosa) (1.4.2)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from librosa) (4.4.2)\n",
            "Requirement already satisfied: numba>=0.51.0 in /usr/local/lib/python3.10/dist-packages (from librosa) (0.60.0)\n",
            "Requirement already satisfied: soundfile>=0.12.1 in /usr/local/lib/python3.10/dist-packages (from librosa) (0.12.1)\n",
            "Requirement already satisfied: pooch>=1.1 in /usr/local/lib/python3.10/dist-packages (from librosa) (1.8.2)\n",
            "Requirement already satisfied: soxr>=0.3.2 in /usr/local/lib/python3.10/dist-packages (from librosa) (0.5.0.post1)\n",
            "Requirement already satisfied: lazy-loader>=0.1 in /usr/local/lib/python3.10/dist-packages (from librosa) (0.4)\n",
            "Requirement already satisfied: msgpack>=1.0 in /usr/local/lib/python3.10/dist-packages (from librosa) (1.0.8)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.1)\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba>=0.51.0->librosa) (0.43.0)\n",
            "Requirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.10/dist-packages (from pooch>=1.1->librosa) (4.3.6)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.8.30)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.20.0->librosa) (3.5.0)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.10/dist-packages (from soundfile>=0.12.1->librosa) (1.17.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.0->soundfile>=0.12.1->librosa) (2.22)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch==2.4.1->torchaudio) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch==2.4.1->torchaudio) (1.3.0)\n",
            "GPU is available and will be used.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING: feature_extractor_cqt requires the libray 'nnAudio'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at m-a-p/MERT-v1-330M were not used when initializing MERTModel: ['encoder.pos_conv_embed.conv.weight_g', 'encoder.pos_conv_embed.conv.weight_v']\n",
            "- This IS expected if you are initializing MERTModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing MERTModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of MERTModel were not initialized from the model checkpoint at m-a-p/MERT-v1-330M and are newly initialized: ['encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from keras.models import Sequential\n",
        "from keras.layers import LSTM, Dense\n",
        "import ast # Import the ast module\n",
        "\n",
        "# Function to process audio, adjust its length to 5 minutes, extract MERT features, and flatten them\n",
        "def process_audio_and_extract_features(audio_path, label_tensor, df):\n",
        "    # Load the audio file\n",
        "    waveform, sample_rate = torchaudio.load(audio_path)\n",
        "    torch.cuda.empty_cache()\n",
        "    gc.collect()\n",
        "\n",
        "    # Check if the sampling rate is 24kHz\n",
        "    if sample_rate != 24000:\n",
        "        print(f\"Resampling from {sample_rate}Hz to 24000Hz for {audio_path}\")\n",
        "        waveform = torchaudio.transforms.Resample(orig_freq=sample_rate, new_freq=24000)(waveform)\n",
        "    else:\n",
        "        print(f\"Audio already in 24kHz for {audio_path}\")\n",
        "\n",
        "    # Ensure waveform is mono by averaging channels if needed\n",
        "    if waveform.shape[0] > 1:\n",
        "        waveform = waveform.mean(dim=0, keepdim=True)\n",
        "\n",
        "    # Determine the required length for 5 minutes in samples\n",
        "    target_samples = 300 * 24000  # 5 minutes * 16000 samples per second\n",
        "\n",
        "    # Truncate or pad waveform to make it exactly 5 minutes\n",
        "    num_samples = waveform.shape[1]\n",
        "    if num_samples > target_samples:\n",
        "        waveform = waveform[:, :target_samples]  # Truncate to 5 minutes\n",
        "    elif num_samples < target_samples:\n",
        "        padding = target_samples - num_samples\n",
        "        waveform = torch.nn.functional.pad(waveform, (0, padding))  # Pad to 5 minutes\n",
        "\n",
        "    print(f\"Adjusted waveform shape: {waveform.shape}\")\n",
        "\n",
        "    # Move waveform to the device (GPU if available)\n",
        "    waveform = waveform.to(device)\n",
        "\n",
        "    # Extract MERT features\n",
        "    with torch.no_grad():\n",
        "        mert_features = None  # Initialize to avoid UnboundLocalError\n",
        "        try:\n",
        "            outputs = model(waveform)\n",
        "            mert_features = outputs.last_hidden_state.squeeze().to(device)\n",
        "            print(mert_features.shape)\n",
        "            # Apply average pooling on the features\n",
        "            # Assuming mert_features has shape [22499, 1024]\n",
        "            # Reshape to (batch_size, channels, length)\n",
        "            mert_features_reshaped = mert_features.permute(1, 0).unsqueeze(0)  # Shape: [1, 1024, 22499]\n",
        "            # Define a new window size based on your requirements (e.g., pooling every 10 seconds)\n",
        "            window_size = 749  # Adjust this as needed\n",
        "\n",
        "            # Apply average pooling along the time dimension (length)\n",
        "            pooled_features = F.avg_pool1d(mert_features_reshaped, kernel_size=window_size, stride=window_size)\n",
        "\n",
        "            # Remove the unnecessary dimensions (if needed)\n",
        "            pooled_features = pooled_features.squeeze(0).permute(1, 0)  # Shape: [num_pooled_windows, 1024]\n",
        "\n",
        "\n",
        "            print(pooled_features.shape)\n",
        "            # Convert mert_features and label to list formats for the DataFrame\n",
        "            mert_features_list = pooled_features.tolist()\n",
        "            rows = len(mert_features_list)\n",
        "            columns = len(mert_features_list[0]) if rows > 0 else 0  # Check for empty lists\n",
        "            print(\"Shape:\", (rows, columns))  # Output: (3, 3)\n",
        "            mood_label = label_tensor.item()  # Extract scalar from label tensor\n",
        "\n",
        "            # Create a new DataFrame row and append it\n",
        "            new_row = pd.DataFrame({\n",
        "                'mert_feature_vector': [mert_features_list],\n",
        "                'mood': [mood_label]\n",
        "            })\n",
        "            df = pd.concat([df, new_row], ignore_index=True)\n",
        "\n",
        "        except RuntimeError as e:\n",
        "            print(\"RuntimeError:\", e)\n",
        "            if \"CUDA out of memory\" in str(e):\n",
        "                print(\"Out of memory error. Try reducing the input size or batch size.\")\n",
        "                return None\n",
        "\n",
        "    print(f\"MERT features shape for {audio_path}: {mert_features.shape}\")\n",
        "    torch.cuda.empty_cache()\n",
        "    return df\n",
        "\n",
        "# Directory structure and DataFrame setup\n",
        "audio_dir = './sample_data/test'  # Replace with your audio files directory\n",
        "emotion_labels = ['anxiety','exuberance','depression','contentment']  # Define your emotions\n",
        "label_to_index = {'anxiety': 0, 'exuberance': 1, 'depression': 2, 'contentment': 3}\n",
        "df = pd.DataFrame(columns=['mert_feature_vector', 'mood'])  # Initialize DataFrame\n",
        "\n",
        "counter=0\n",
        "# Process each song, extract features, and add them to the DataFrame\n",
        "for label in emotion_labels:\n",
        "    label_dir = os.path.join(audio_dir, label)\n",
        "    print(f\"Processing label directory: {label_dir}\")\n",
        "    for filename in os.listdir(label_dir):\n",
        "        if filename.endswith('.mp3'):  # Adjust for your file format\n",
        "            audio_path = os.path.join(label_dir, filename)\n",
        "            label_tensor = torch.tensor([label_to_index[label]], dtype=torch.float32).to(device)\n",
        "\n",
        "            # Process and extract MERT features, updating the DataFrame\n",
        "            df = process_audio_and_extract_features(audio_path, label_tensor, df)\n",
        "            print(f\"Adding features for {filename} with label {label}\")\n",
        "            print(f\"Processed file: {filename}\")\n",
        "            counter+=1\n",
        "            print(counter)\n",
        "\n",
        "print(\"Final DataFrame:\")\n",
        "print(df.head())\n",
        "\n",
        "# Assuming df is your DataFrame that you've been working with\n",
        "print(df.tail(5))  # Optionally, print the last 5 rows to inspect the data\n",
        "print(\"Shape of the DataFrame:\", df.shape)\n",
        "\n",
        "# Check if DataFrame is empty\n",
        "if df.empty:\n",
        "    print(\"Error: DataFrame is empty. No data to save.\")\n",
        "else:\n",
        "    # If the DataFrame has data, append to CSV or create a new one\n",
        "    csv_file = './test mert_song_features_for 750 window size.csv'\n",
        "\n",
        "    if os.path.exists(csv_file):\n",
        "        df.to_csv(csv_file, mode='a', header=False, index=False)  # Append without header\n",
        "        print(\"Data appended to existing CSV.\")\n",
        "    else:\n",
        "        df.to_csv(csv_file, mode='w', header=True, index=False)  # Write with header\n",
        "        print(\"DataFrame saved as new CSV.\")\n",
        "\n",
        "    print(\"DataFrame saved successfully.\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p3J2yeBUk_mh",
        "outputId": "370a1ea5-769d-4334-d521-e83d04f533ec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing label directory: ./sample_data/test/anxiety\n",
            "Resampling from 44100Hz to 24000Hz for ./sample_data/test/anxiety/Veera-Soora.mp3\n",
            "Adjusted waveform shape: torch.Size([1, 7200000])\n",
            "torch.Size([22499, 1024])\n",
            "torch.Size([30, 1024])\n",
            "Shape: (30, 1024)\n",
            "MERT features shape for ./sample_data/test/anxiety/Veera-Soora.mp3: torch.Size([22499, 1024])\n",
            "Adding features for Veera-Soora.mp3 with label anxiety\n",
            "Processed file: Veera-Soora.mp3\n",
            "1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-6-86e3bf55531e>:76: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
            "  df = pd.concat([df, new_row], ignore_index=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Resampling from 44100Hz to 24000Hz for ./sample_data/test/anxiety/Vijana-Surabhi.mp3\n",
            "Adjusted waveform shape: torch.Size([1, 7200000])\n",
            "torch.Size([22499, 1024])\n",
            "torch.Size([30, 1024])\n",
            "Shape: (30, 1024)\n",
            "MERT features shape for ./sample_data/test/anxiety/Vijana-Surabhi.mp3: torch.Size([22499, 1024])\n",
            "Adding features for Vijana-Surabhi.mp3 with label anxiety\n",
            "Processed file: Vijana-Surabhi.mp3\n",
            "2\n",
            "Resampling from 44100Hz to 24000Hz for ./sample_data/test/anxiety/Sattru-Munbu.mp3\n",
            "Adjusted waveform shape: torch.Size([1, 7200000])\n",
            "torch.Size([22499, 1024])\n",
            "torch.Size([30, 1024])\n",
            "Shape: (30, 1024)\n",
            "MERT features shape for ./sample_data/test/anxiety/Sattru-Munbu.mp3: torch.Size([22499, 1024])\n",
            "Adding features for Sattru-Munbu.mp3 with label anxiety\n",
            "Processed file: Sattru-Munbu.mp3\n",
            "3\n",
            "Resampling from 44100Hz to 24000Hz for ./sample_data/test/anxiety/Yevarini Adaganu.mp3\n",
            "Adjusted waveform shape: torch.Size([1, 7200000])\n",
            "torch.Size([22499, 1024])\n",
            "torch.Size([30, 1024])\n",
            "Shape: (30, 1024)\n",
            "MERT features shape for ./sample_data/test/anxiety/Yevarini Adaganu.mp3: torch.Size([22499, 1024])\n",
            "Adding features for Yevarini Adaganu.mp3 with label anxiety\n",
            "Processed file: Yevarini Adaganu.mp3\n",
            "4\n",
            "Resampling from 44100Hz to 24000Hz for ./sample_data/test/anxiety/Toliprema.mp3\n",
            "Adjusted waveform shape: torch.Size([1, 7200000])\n",
            "torch.Size([22499, 1024])\n",
            "torch.Size([30, 1024])\n",
            "Shape: (30, 1024)\n",
            "MERT features shape for ./sample_data/test/anxiety/Toliprema.mp3: torch.Size([22499, 1024])\n",
            "Adding features for Toliprema.mp3 with label anxiety\n",
            "Processed file: Toliprema.mp3\n",
            "5\n",
            "Resampling from 44100Hz to 24000Hz for ./sample_data/test/anxiety/Telisiney Na Nuvvey.mp3\n",
            "Adjusted waveform shape: torch.Size([1, 7200000])\n",
            "torch.Size([22499, 1024])\n",
            "torch.Size([30, 1024])\n",
            "Shape: (30, 1024)\n",
            "MERT features shape for ./sample_data/test/anxiety/Telisiney Na Nuvvey.mp3: torch.Size([22499, 1024])\n",
            "Adding features for Telisiney Na Nuvvey.mp3 with label anxiety\n",
            "Processed file: Telisiney Na Nuvvey.mp3\n",
            "6\n",
            "Resampling from 44100Hz to 24000Hz for ./sample_data/test/anxiety/Vellipomaakey.mp3\n",
            "Adjusted waveform shape: torch.Size([1, 7200000])\n",
            "torch.Size([22499, 1024])\n",
            "torch.Size([30, 1024])\n",
            "Shape: (30, 1024)\n",
            "MERT features shape for ./sample_data/test/anxiety/Vellipomaakey.mp3: torch.Size([22499, 1024])\n",
            "Adding features for Vellipomaakey.mp3 with label anxiety\n",
            "Processed file: Vellipomaakey.mp3\n",
            "7\n",
            "Resampling from 48000Hz to 24000Hz for ./sample_data/test/anxiety/Vivegam-Surviva(PagalWorldl).mp3\n",
            "Adjusted waveform shape: torch.Size([1, 7200000])\n",
            "torch.Size([22499, 1024])\n",
            "torch.Size([30, 1024])\n",
            "Shape: (30, 1024)\n",
            "MERT features shape for ./sample_data/test/anxiety/Vivegam-Surviva(PagalWorldl).mp3: torch.Size([22499, 1024])\n",
            "Adding features for Vivegam-Surviva(PagalWorldl).mp3 with label anxiety\n",
            "Processed file: Vivegam-Surviva(PagalWorldl).mp3\n",
            "8\n",
            "Resampling from 44100Hz to 24000Hz for ./sample_data/test/anxiety/Uyire-Uyire.mp3\n",
            "Adjusted waveform shape: torch.Size([1, 7200000])\n",
            "torch.Size([22499, 1024])\n",
            "torch.Size([30, 1024])\n",
            "Shape: (30, 1024)\n",
            "MERT features shape for ./sample_data/test/anxiety/Uyire-Uyire.mp3: torch.Size([22499, 1024])\n",
            "Adding features for Uyire-Uyire.mp3 with label anxiety\n",
            "Processed file: Uyire-Uyire.mp3\n",
            "9\n",
            "Resampling from 44100Hz to 24000Hz for ./sample_data/test/anxiety/Urime Manase.mp3\n",
            "Adjusted waveform shape: torch.Size([1, 7200000])\n",
            "torch.Size([22499, 1024])\n",
            "torch.Size([30, 1024])\n",
            "Shape: (30, 1024)\n",
            "MERT features shape for ./sample_data/test/anxiety/Urime Manase.mp3: torch.Size([22499, 1024])\n",
            "Adding features for Urime Manase.mp3 with label anxiety\n",
            "Processed file: Urime Manase.mp3\n",
            "10\n",
            "Processing label directory: ./sample_data/test/exuberance\n",
            "Resampling from 44100Hz to 24000Hz for ./sample_data/test/exuberance/Thaai-Kelavi.mp3\n",
            "Adjusted waveform shape: torch.Size([1, 7200000])\n",
            "torch.Size([22499, 1024])\n",
            "torch.Size([30, 1024])\n",
            "Shape: (30, 1024)\n",
            "MERT features shape for ./sample_data/test/exuberance/Thaai-Kelavi.mp3: torch.Size([22499, 1024])\n",
            "Adding features for Thaai-Kelavi.mp3 with label exuberance\n",
            "Processed file: Thaai-Kelavi.mp3\n",
            "11\n",
            "Resampling from 44100Hz to 24000Hz for ./sample_data/test/exuberance/Vilambara-Idaiveli-MassTamilan.mp3\n",
            "Adjusted waveform shape: torch.Size([1, 7200000])\n",
            "torch.Size([22499, 1024])\n",
            "torch.Size([30, 1024])\n",
            "Shape: (30, 1024)\n",
            "MERT features shape for ./sample_data/test/exuberance/Vilambara-Idaiveli-MassTamilan.mp3: torch.Size([22499, 1024])\n",
            "Adding features for Vilambara-Idaiveli-MassTamilan.mp3 with label exuberance\n",
            "Processed file: Vilambara-Idaiveli-MassTamilan.mp3\n",
            "12\n",
            "Resampling from 44100Hz to 24000Hz for ./sample_data/test/exuberance/Ranjithame-MassTamilan.mp3\n",
            "Adjusted waveform shape: torch.Size([1, 7200000])\n",
            "torch.Size([22499, 1024])\n",
            "torch.Size([30, 1024])\n",
            "Shape: (30, 1024)\n",
            "MERT features shape for ./sample_data/test/exuberance/Ranjithame-MassTamilan.mp3: torch.Size([22499, 1024])\n",
            "Adding features for Ranjithame-MassTamilan.mp3 with label exuberance\n",
            "Processed file: Ranjithame-MassTamilan.mp3\n",
            "13\n",
            "Resampling from 44100Hz to 24000Hz for ./sample_data/test/exuberance/Rang De.mp3\n",
            "Adjusted waveform shape: torch.Size([1, 7200000])\n",
            "torch.Size([22499, 1024])\n",
            "torch.Size([30, 1024])\n",
            "Shape: (30, 1024)\n",
            "MERT features shape for ./sample_data/test/exuberance/Rang De.mp3: torch.Size([22499, 1024])\n",
            "Adding features for Rang De.mp3 with label exuberance\n",
            "Processed file: Rang De.mp3\n",
            "14\n",
            "Resampling from 44100Hz to 24000Hz for ./sample_data/test/exuberance/Takkunu-Takkunu-MassTamilan.mp3\n",
            "Adjusted waveform shape: torch.Size([1, 7200000])\n",
            "torch.Size([22499, 1024])\n",
            "torch.Size([30, 1024])\n",
            "Shape: (30, 1024)\n",
            "MERT features shape for ./sample_data/test/exuberance/Takkunu-Takkunu-MassTamilan.mp3: torch.Size([22499, 1024])\n",
            "Adding features for Takkunu-Takkunu-MassTamilan.mp3 with label exuberance\n",
            "Processed file: Takkunu-Takkunu-MassTamilan.mp3\n",
            "15\n",
            "Resampling from 44100Hz to 24000Hz for ./sample_data/test/exuberance/SarangaDariya.mp3\n",
            "Adjusted waveform shape: torch.Size([1, 7200000])\n",
            "torch.Size([22499, 1024])\n",
            "torch.Size([30, 1024])\n",
            "Shape: (30, 1024)\n",
            "MERT features shape for ./sample_data/test/exuberance/SarangaDariya.mp3: torch.Size([22499, 1024])\n",
            "Adding features for SarangaDariya.mp3 with label exuberance\n",
            "Processed file: SarangaDariya.mp3\n",
            "16\n",
            "Resampling from 44100Hz to 24000Hz for ./sample_data/test/exuberance/Vaathi-Coming-MassTamilan.io.mp3\n",
            "Adjusted waveform shape: torch.Size([1, 7200000])\n",
            "torch.Size([22499, 1024])\n",
            "torch.Size([30, 1024])\n",
            "Shape: (30, 1024)\n",
            "MERT features shape for ./sample_data/test/exuberance/Vaathi-Coming-MassTamilan.io.mp3: torch.Size([22499, 1024])\n",
            "Adding features for Vaathi-Coming-MassTamilan.io.mp3 with label exuberance\n",
            "Processed file: Vaathi-Coming-MassTamilan.io.mp3\n",
            "17\n",
            "Resampling from 44100Hz to 24000Hz for ./sample_data/test/exuberance/Senthoora.mp3\n",
            "Adjusted waveform shape: torch.Size([1, 7200000])\n",
            "torch.Size([22499, 1024])\n",
            "torch.Size([30, 1024])\n",
            "Shape: (30, 1024)\n",
            "MERT features shape for ./sample_data/test/exuberance/Senthoora.mp3: torch.Size([22499, 1024])\n",
            "Adding features for Senthoora.mp3 with label exuberance\n",
            "Processed file: Senthoora.mp3\n",
            "18\n",
            "Resampling from 48000Hz to 24000Hz for ./sample_data/test/exuberance/Thudakam Mangalyam.mp3\n",
            "Adjusted waveform shape: torch.Size([1, 7200000])\n",
            "torch.Size([22499, 1024])\n",
            "torch.Size([30, 1024])\n",
            "Shape: (30, 1024)\n",
            "MERT features shape for ./sample_data/test/exuberance/Thudakam Mangalyam.mp3: torch.Size([22499, 1024])\n",
            "Adding features for Thudakam Mangalyam.mp3 with label exuberance\n",
            "Processed file: Thudakam Mangalyam.mp3\n",
            "19\n",
            "Resampling from 44100Hz to 24000Hz for ./sample_data/test/exuberance/Vachinde.mp3\n",
            "Adjusted waveform shape: torch.Size([1, 7200000])\n",
            "torch.Size([22499, 1024])\n",
            "torch.Size([30, 1024])\n",
            "Shape: (30, 1024)\n",
            "MERT features shape for ./sample_data/test/exuberance/Vachinde.mp3: torch.Size([22499, 1024])\n",
            "Adding features for Vachinde.mp3 with label exuberance\n",
            "Processed file: Vachinde.mp3\n",
            "20\n",
            "Resampling from 44100Hz to 24000Hz for ./sample_data/test/exuberance/Rowdy-Baby-MassTamilan.mp3\n",
            "Adjusted waveform shape: torch.Size([1, 7200000])\n",
            "torch.Size([22499, 1024])\n",
            "torch.Size([30, 1024])\n",
            "Shape: (30, 1024)\n",
            "MERT features shape for ./sample_data/test/exuberance/Rowdy-Baby-MassTamilan.mp3: torch.Size([22499, 1024])\n",
            "Adding features for Rowdy-Baby-MassTamilan.mp3 with label exuberance\n",
            "Processed file: Rowdy-Baby-MassTamilan.mp3\n",
            "21\n",
            "Processing label directory: ./sample_data/test/depression\n",
            "Resampling from 44100Hz to 24000Hz for ./sample_data/test/depression/Undiporaadhey.mp3\n",
            "Adjusted waveform shape: torch.Size([1, 7200000])\n",
            "torch.Size([22499, 1024])\n",
            "torch.Size([30, 1024])\n",
            "Shape: (30, 1024)\n",
            "MERT features shape for ./sample_data/test/depression/Undiporaadhey.mp3: torch.Size([22499, 1024])\n",
            "Adding features for Undiporaadhey.mp3 with label depression\n",
            "Processed file: Undiporaadhey.mp3\n",
            "22\n",
            "Resampling from 44100Hz to 24000Hz for ./sample_data/test/depression/Raapadee-Kezhunnuvo.mp3\n",
            "Adjusted waveform shape: torch.Size([1, 7200000])\n",
            "torch.Size([22499, 1024])\n",
            "torch.Size([30, 1024])\n",
            "Shape: (30, 1024)\n",
            "MERT features shape for ./sample_data/test/depression/Raapadee-Kezhunnuvo.mp3: torch.Size([22499, 1024])\n",
            "Adding features for Raapadee-Kezhunnuvo.mp3 with label depression\n",
            "Processed file: Raapadee-Kezhunnuvo.mp3\n",
            "23\n",
            "Resampling from 44100Hz to 24000Hz for ./sample_data/test/depression/Selavanuko.mp3\n",
            "Adjusted waveform shape: torch.Size([1, 7200000])\n",
            "torch.Size([22499, 1024])\n",
            "torch.Size([30, 1024])\n",
            "Shape: (30, 1024)\n",
            "MERT features shape for ./sample_data/test/depression/Selavanuko.mp3: torch.Size([22499, 1024])\n",
            "Adding features for Selavanuko.mp3 with label depression\n",
            "Processed file: Selavanuko.mp3\n",
            "24\n",
            "Resampling from 44100Hz to 24000Hz for ./sample_data/test/depression/Sidhoora-Sandhye.mp3\n",
            "Adjusted waveform shape: torch.Size([1, 7200000])\n",
            "torch.Size([22499, 1024])\n",
            "torch.Size([30, 1024])\n",
            "Shape: (30, 1024)\n",
            "MERT features shape for ./sample_data/test/depression/Sidhoora-Sandhye.mp3: torch.Size([22499, 1024])\n",
            "Adding features for Sidhoora-Sandhye.mp3 with label depression\n",
            "Processed file: Sidhoora-Sandhye.mp3\n",
            "25\n",
            "Resampling from 44100Hz to 24000Hz for ./sample_data/test/depression/Yetu Pone.mp3\n",
            "Adjusted waveform shape: torch.Size([1, 7200000])\n",
            "torch.Size([22499, 1024])\n",
            "torch.Size([30, 1024])\n",
            "Shape: (30, 1024)\n",
            "MERT features shape for ./sample_data/test/depression/Yetu Pone.mp3: torch.Size([22499, 1024])\n",
            "Adding features for Yetu Pone.mp3 with label depression\n",
            "Processed file: Yetu Pone.mp3\n",
            "26\n",
            "Resampling from 48000Hz to 24000Hz for ./sample_data/test/depression/Veshangal-Janmangal-1.mp3\n",
            "Adjusted waveform shape: torch.Size([1, 7200000])\n",
            "torch.Size([22499, 1024])\n",
            "torch.Size([30, 1024])\n",
            "Shape: (30, 1024)\n",
            "MERT features shape for ./sample_data/test/depression/Veshangal-Janmangal-1.mp3: torch.Size([22499, 1024])\n",
            "Adding features for Veshangal-Janmangal-1.mp3 with label depression\n",
            "Processed file: Veshangal-Janmangal-1.mp3\n",
            "27\n",
            "Resampling from 44100Hz to 24000Hz for ./sample_data/test/depression/Unakkena-Iruppen.mp3\n",
            "Adjusted waveform shape: torch.Size([1, 7200000])\n",
            "torch.Size([22499, 1024])\n",
            "torch.Size([30, 1024])\n",
            "Shape: (30, 1024)\n",
            "MERT features shape for ./sample_data/test/depression/Unakkena-Iruppen.mp3: torch.Size([22499, 1024])\n",
            "Adding features for Unakkena-Iruppen.mp3 with label depression\n",
            "Processed file: Unakkena-Iruppen.mp3\n",
            "28\n",
            "Resampling from 44100Hz to 24000Hz for ./sample_data/test/depression/Uyirilae.mp3\n",
            "Adjusted waveform shape: torch.Size([1, 7200000])\n",
            "torch.Size([22499, 1024])\n",
            "torch.Size([30, 1024])\n",
            "Shape: (30, 1024)\n",
            "MERT features shape for ./sample_data/test/depression/Uyirilae.mp3: torch.Size([22499, 1024])\n",
            "Adding features for Uyirilae.mp3 with label depression\n",
            "Processed file: Uyirilae.mp3\n",
            "29\n",
            "Resampling from 44100Hz to 24000Hz for ./sample_data/test/depression/Swapnam-Thyajichal-K-J-Yesudas-K-S-Chithra-Ashwathi-Vijayan.mp3\n",
            "Adjusted waveform shape: torch.Size([1, 7200000])\n",
            "torch.Size([22499, 1024])\n",
            "torch.Size([30, 1024])\n",
            "Shape: (30, 1024)\n",
            "MERT features shape for ./sample_data/test/depression/Swapnam-Thyajichal-K-J-Yesudas-K-S-Chithra-Ashwathi-Vijayan.mp3: torch.Size([22499, 1024])\n",
            "Adding features for Swapnam-Thyajichal-K-J-Yesudas-K-S-Chithra-Ashwathi-Vijayan.mp3 with label depression\n",
            "Processed file: Swapnam-Thyajichal-K-J-Yesudas-K-S-Chithra-Ashwathi-Vijayan.mp3\n",
            "30\n",
            "Resampling from 44100Hz to 24000Hz for ./sample_data/test/depression/Yaaro-Yaaro.mp3\n",
            "Adjusted waveform shape: torch.Size([1, 7200000])\n",
            "torch.Size([22499, 1024])\n",
            "torch.Size([30, 1024])\n",
            "Shape: (30, 1024)\n",
            "MERT features shape for ./sample_data/test/depression/Yaaro-Yaaro.mp3: torch.Size([22499, 1024])\n",
            "Adding features for Yaaro-Yaaro.mp3 with label depression\n",
            "Processed file: Yaaro-Yaaro.mp3\n",
            "31\n",
            "Resampling from 44100Hz to 24000Hz for ./sample_data/test/depression/Soorya-Kireedam.mp3\n",
            "Adjusted waveform shape: torch.Size([1, 7200000])\n",
            "torch.Size([22499, 1024])\n",
            "torch.Size([30, 1024])\n",
            "Shape: (30, 1024)\n",
            "MERT features shape for ./sample_data/test/depression/Soorya-Kireedam.mp3: torch.Size([22499, 1024])\n",
            "Adding features for Soorya-Kireedam.mp3 with label depression\n",
            "Processed file: Soorya-Kireedam.mp3\n",
            "32\n",
            "Resampling from 44100Hz to 24000Hz for ./sample_data/test/depression/Thoondil Meen.mp3\n",
            "Adjusted waveform shape: torch.Size([1, 7200000])\n",
            "torch.Size([22499, 1024])\n",
            "torch.Size([30, 1024])\n",
            "Shape: (30, 1024)\n",
            "MERT features shape for ./sample_data/test/depression/Thoondil Meen.mp3: torch.Size([22499, 1024])\n",
            "Adding features for Thoondil Meen.mp3 with label depression\n",
            "Processed file: Thoondil Meen.mp3\n",
            "33\n",
            "Resampling from 44100Hz to 24000Hz for ./sample_data/test/depression/Yedetthu Mallele.mp3\n",
            "Adjusted waveform shape: torch.Size([1, 7200000])\n",
            "torch.Size([22499, 1024])\n",
            "torch.Size([30, 1024])\n",
            "Shape: (30, 1024)\n",
            "MERT features shape for ./sample_data/test/depression/Yedetthu Mallele.mp3: torch.Size([22499, 1024])\n",
            "Adding features for Yedetthu Mallele.mp3 with label depression\n",
            "Processed file: Yedetthu Mallele.mp3\n",
            "34\n",
            "Processing label directory: ./sample_data/test/contentment\n",
            "Resampling from 44100Hz to 24000Hz for ./sample_data/test/contentment/Uyire-Sid-Sriram.mp3\n",
            "Adjusted waveform shape: torch.Size([1, 7200000])\n",
            "torch.Size([22499, 1024])\n",
            "torch.Size([30, 1024])\n",
            "Shape: (30, 1024)\n",
            "MERT features shape for ./sample_data/test/contentment/Uyire-Sid-Sriram.mp3: torch.Size([22499, 1024])\n",
            "Adding features for Uyire-Sid-Sriram.mp3 with label contentment\n",
            "Processed file: Uyire-Sid-Sriram.mp3\n",
            "35\n",
            "Resampling from 44100Hz to 24000Hz for ./sample_data/test/contentment/Urike Urike.mp3\n",
            "Adjusted waveform shape: torch.Size([1, 7200000])\n",
            "torch.Size([22499, 1024])\n",
            "torch.Size([30, 1024])\n",
            "Shape: (30, 1024)\n",
            "MERT features shape for ./sample_data/test/contentment/Urike Urike.mp3: torch.Size([22499, 1024])\n",
            "Adding features for Urike Urike.mp3 with label contentment\n",
            "Processed file: Urike Urike.mp3\n",
            "36\n",
            "Resampling from 44100Hz to 24000Hz for ./sample_data/test/contentment/Priya Mithunam.mp3\n",
            "Adjusted waveform shape: torch.Size([1, 7200000])\n",
            "torch.Size([22499, 1024])\n",
            "torch.Size([30, 1024])\n",
            "Shape: (30, 1024)\n",
            "MERT features shape for ./sample_data/test/contentment/Priya Mithunam.mp3: torch.Size([22499, 1024])\n",
            "Adding features for Priya Mithunam.mp3 with label contentment\n",
            "Processed file: Priya Mithunam.mp3\n",
            "37\n",
            "Resampling from 48000Hz to 24000Hz for ./sample_data/test/contentment/Thankamanasin Peelikadavile _ Sundarapurushan _ 1080p Remastered Song _ Suresh Gopi _ Devayani.mp3\n",
            "Adjusted waveform shape: torch.Size([1, 7200000])\n",
            "torch.Size([22499, 1024])\n",
            "torch.Size([30, 1024])\n",
            "Shape: (30, 1024)\n",
            "MERT features shape for ./sample_data/test/contentment/Thankamanasin Peelikadavile _ Sundarapurushan _ 1080p Remastered Song _ Suresh Gopi _ Devayani.mp3: torch.Size([22499, 1024])\n",
            "Adding features for Thankamanasin Peelikadavile _ Sundarapurushan _ 1080p Remastered Song _ Suresh Gopi _ Devayani.mp3 with label contentment\n",
            "Processed file: Thankamanasin Peelikadavile _ Sundarapurushan _ 1080p Remastered Song _ Suresh Gopi _ Devayani.mp3\n",
            "38\n",
            "Resampling from 48000Hz to 24000Hz for ./sample_data/test/contentment/Punchiri-Thanjum.mp3\n",
            "Adjusted waveform shape: torch.Size([1, 7200000])\n",
            "torch.Size([22499, 1024])\n",
            "torch.Size([30, 1024])\n",
            "Shape: (30, 1024)\n",
            "MERT features shape for ./sample_data/test/contentment/Punchiri-Thanjum.mp3: torch.Size([22499, 1024])\n",
            "Adding features for Punchiri-Thanjum.mp3 with label contentment\n",
            "Processed file: Punchiri-Thanjum.mp3\n",
            "39\n",
            "Resampling from 44100Hz to 24000Hz for ./sample_data/test/contentment/Sirukki-Vaasam.mp3\n",
            "Adjusted waveform shape: torch.Size([1, 7200000])\n",
            "torch.Size([22499, 1024])\n",
            "torch.Size([30, 1024])\n",
            "Shape: (30, 1024)\n",
            "MERT features shape for ./sample_data/test/contentment/Sirukki-Vaasam.mp3: torch.Size([22499, 1024])\n",
            "Adding features for Sirukki-Vaasam.mp3 with label contentment\n",
            "Processed file: Sirukki-Vaasam.mp3\n",
            "40\n",
            "Resampling from 44100Hz to 24000Hz for ./sample_data/test/contentment/Vaa-Vaa-Vo-Vaave.mp3\n",
            "Adjusted waveform shape: torch.Size([1, 7200000])\n",
            "torch.Size([22499, 1024])\n",
            "torch.Size([30, 1024])\n",
            "Shape: (30, 1024)\n",
            "MERT features shape for ./sample_data/test/contentment/Vaa-Vaa-Vo-Vaave.mp3: torch.Size([22499, 1024])\n",
            "Adding features for Vaa-Vaa-Vo-Vaave.mp3 with label contentment\n",
            "Processed file: Vaa-Vaa-Vo-Vaave.mp3\n",
            "41\n",
            "Resampling from 44100Hz to 24000Hz for ./sample_data/test/contentment/Poove-Poove-Palappoove-P-Jayachandran-K-S-Chithra.mp3\n",
            "Adjusted waveform shape: torch.Size([1, 7200000])\n",
            "torch.Size([22499, 1024])\n",
            "torch.Size([30, 1024])\n",
            "Shape: (30, 1024)\n",
            "MERT features shape for ./sample_data/test/contentment/Poove-Poove-Palappoove-P-Jayachandran-K-S-Chithra.mp3: torch.Size([22499, 1024])\n",
            "Adding features for Poove-Poove-Palappoove-P-Jayachandran-K-S-Chithra.mp3 with label contentment\n",
            "Processed file: Poove-Poove-Palappoove-P-Jayachandran-K-S-Chithra.mp3\n",
            "42\n",
            "Resampling from 44100Hz to 24000Hz for ./sample_data/test/contentment/Yedurangula Vaana.mp3\n",
            "Adjusted waveform shape: torch.Size([1, 7200000])\n",
            "torch.Size([22499, 1024])\n",
            "torch.Size([30, 1024])\n",
            "Shape: (30, 1024)\n",
            "MERT features shape for ./sample_data/test/contentment/Yedurangula Vaana.mp3: torch.Size([22499, 1024])\n",
            "Adding features for Yedurangula Vaana.mp3 with label contentment\n",
            "Processed file: Yedurangula Vaana.mp3\n",
            "43\n",
            "Resampling from 44100Hz to 24000Hz for ./sample_data/test/contentment/Vaseegara.mp3\n",
            "Adjusted waveform shape: torch.Size([1, 7200000])\n",
            "torch.Size([22499, 1024])\n",
            "torch.Size([30, 1024])\n",
            "Shape: (30, 1024)\n",
            "MERT features shape for ./sample_data/test/contentment/Vaseegara.mp3: torch.Size([22499, 1024])\n",
            "Adding features for Vaseegara.mp3 with label contentment\n",
            "Processed file: Vaseegara.mp3\n",
            "44\n",
            "Resampling from 44100Hz to 24000Hz for ./sample_data/test/contentment/Suttum-Vizhi.mp3\n",
            "Adjusted waveform shape: torch.Size([1, 7200000])\n",
            "torch.Size([22499, 1024])\n",
            "torch.Size([30, 1024])\n",
            "Shape: (30, 1024)\n",
            "MERT features shape for ./sample_data/test/contentment/Suttum-Vizhi.mp3: torch.Size([22499, 1024])\n",
            "Adding features for Suttum-Vizhi.mp3 with label contentment\n",
            "Processed file: Suttum-Vizhi.mp3\n",
            "45\n",
            "Final DataFrame:\n",
            "                                 mert_feature_vector  mood\n",
            "0  [[-0.09135907888412476, 0.012904385104775429, ...   0.0\n",
            "1  [[-0.08156260848045349, 0.15602581202983856, 0...   0.0\n",
            "2  [[0.13176263868808746, 0.10024379938840866, -0...   0.0\n",
            "3  [[-0.031162504106760025, 0.1877439171075821, -...   0.0\n",
            "4  [[-0.07002820819616318, 0.05296378210186958, -...   0.0\n",
            "                                  mert_feature_vector  mood\n",
            "40  [[-0.03998589143157005, -0.04668039456009865, ...   3.0\n",
            "41  [[0.04867124184966087, 0.11980415135622025, 0....   3.0\n",
            "42  [[-0.06023094430565834, 0.16380088031291962, -...   3.0\n",
            "43  [[-0.03904975205659866, 0.19322754442691803, 0...   3.0\n",
            "44  [[0.009388959035277367, -0.06635857373476028, ...   3.0\n",
            "Shape of the DataFrame: (45, 2)\n",
            "DataFrame saved as new CSV.\n",
            "DataFrame saved successfully.\n"
          ]
        }
      ]
    }
  ]
}